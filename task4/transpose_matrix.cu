#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>
#include <stdlib.h>
// размер блока
#define BLOCK_SIZE 16
// тип, который будут иметь элементы матриц
#define BASE_TYPE float
// Ядро
// Функция транспонирования матрицы
__global__ void matrixTranspose(const BASE_TYPE *A,
BASE_TYPE *AT, int rows, int cols)
{
    // Индекс элемента в исходной матрице
    int iA = cols * (blockDim.y * blockIdx.y +
    threadIdx.y) + blockDim.x * blockIdx.x +
    threadIdx.x;
    // Индекс соответствующего элемента в
    // транспонированной матрице
    int iAT = rows * (blockDim.x * blockIdx.x + threadIdx.x) + blockDim.y * blockIdx.y + threadIdx.y;
    AT[iAT] = A[iA];
}
// Функция вычисления числа, которое больше числа а
// и кратное числу b
int toMultiple(int a, int b)
{
    int mod = a % b;
    if (mod != 0)
    {
        mod = b - mod;
        return a + mod;
    }
    return a;
}


int main()
{
    // Объекты событий
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    // Количество строк и столбцов матрицы
    int rows = 1000;
    int cols = 2000;
    // Меняем количество строк и столбцов матрицы
    // на число, кратное размеру блока (16)
    rows = toMultiple(rows, BLOCK_SIZE);
    printf("rows = %d\n", rows);
    cols = toMultiple(cols, BLOCK_SIZE);
    printf("cols = %d\n", cols);
    size_t size = rows * cols * sizeof(BASE_TYPE);
    // Выделение памяти под матрицы на хосте
    // Исходная матрица
    BASE_TYPE *h_A = (BASE_TYPE *)malloc(size);
    // Транспонированная матрица
    BASE_TYPE *h_AT = (BASE_TYPE *)malloc(size);
    // Инициализация матрицы
    for (int i = 0; i < rows * cols; ++i)
    {
        h_A[i] = rand()/(BASE_TYPE)RAND_MAX;
    }
    // Выделение глобальной памяти на девайсе
    // для исходной матрицы
    BASE_TYPE *d_A = NULL;
    cudaMalloc((void **)&d_A, size);
    // Выделение глобальной памяти на девайсе для
    // транспонированной матрицы
    BASE_TYPE *d_AT = NULL;
    cudaMalloc((void **)&d_AT, size);
    // Копируем матрицу из CPU на GPU
    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    // Определяем размер блока и сетки
    dim3 threadsPerBlock = dim3(BLOCK_SIZE, BLOCK_SIZE);
    dim3 blocksPerGrid = dim3(cols / BLOCK_SIZE, rows / BLOCK_SIZE);
    // Начать отсчета времени
    cudaEventRecord( start, 0);
    // Запуск ядра
    matrixTranspose<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_AT, rows, cols);
    // Окончание работы ядра, остановка времени
    cudaEventRecord( stop, 0);
    cudaEventSynchronize( stop );
    float KernelTime;
    cudaEventElapsedTime( &KernelTime, start, stop);
    printf("KernelTime: %.2f milliseconds\n", KernelTime);
    // Копируем матрицу из GPU на CPU
    cudaMemcpy(h_AT, d_AT, size, cudaMemcpyDeviceToHost);
    // Проверка правильности работы ядра
    for (int i = 0; i < rows; i++)
        for (int j = 0; j < cols; j++)
        {
            if (h_A[i * cols + j] != h_AT[j * rows + i])
                fprintf(stderr, "Result verification failed at element [%d, %d]!\n", i, j);
                exit(EXIT_FAILURE);
        }
    printf("Test PASSED\n");
    // Освобождаем память на GPU
    cudaFree(d_A);
    // Освобождаем память на GPU
    cudaFree(d_AT);
    // Освобождаем память на CPU
    free(h_A);
    free(h_AT);
    // Удаляем объекты событий
    cudaEventDestroy( start );
    cudaEventDestroy( stop );
    printf("Done\n");
    return 0;
}
